{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e50c8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras is a library that acts like a wrapper around TensorFlow, provides simple commands to use TensorFlow\n",
    "\n",
    "# keras.datasets is a library of pre-packaged sample data\n",
    "# Import MNIST database, collection of handwritten digits - the \"real\" data\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# A layer is a specific mathematical transformation that data passes through\n",
    "# Input - a placeholder for the starting data\n",
    "# Dense - a standard brick; every neuron in this layer connects to every neuron in the next\n",
    "# Reshape - a morphing brick; changes the data from a flat line into a 2D square\n",
    "# Dropout - a filter brick; randomly turns off neurons to prevent the model from overfitting\n",
    "from keras.layers import Input, Dense, Reshape, Flatten\n",
    "\n",
    "# Standardies the outputs from the previous layer to always have a mean of 0 and a standard deviation of 1\n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "# Standard ReLu turns all negative numbers into zero\n",
    "# Leaky ReLu allows a small percentage of negative signal to pass through, keeps the GAN \"alive\"\n",
    "# Original line - from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers import LeakyReLU\n",
    "\n",
    "# Defines the \"container\" for the layers\n",
    "# Sequential - A simple, linear stack what data flows through each layer\n",
    "# Model - More flexible paths\n",
    "from keras.models import Sequential, Model\n",
    "\n",
    "# The optimizer is the algorithm that updates the model's weights to make it better; Adam is a popular choice\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be1defe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each image in the MNIST dataset is 28x28 pixels.\n",
    "# Define input image dimensions\n",
    "img_rows = 28\n",
    "img_cols = 28\n",
    "\n",
    "# The images are in grayscale, so each pixel has 1 value describing how bright it is (black to white)\n",
    "channels = 1\n",
    "\n",
    "# Creates a tuple defining our image shape\n",
    "img_shape = (img_rows, img_cols, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035b776a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given an input of noise (latent) vector, the Generator will generate an image\n",
    "def build_generator():\n",
    "\n",
    "\t### Sequential API - BUILD THE MODEL ###\n",
    "  \n",
    "\t# Define the noise (seed) to be a vector (1D) of size 100\n",
    "\tnoise_shape = (100,)\n",
    "  \n",
    "\t# Define the generator network\n",
    "  # Note: Current GAN is simple - only uses Dense layers (easy to understand, fast to train) - but don't see shapes well\n",
    "\t#       There are more powerful versions (e.g., VGG for super-resolution GAN)\n",
    "  \n",
    "\t# Creates an empty container to add layers into.\n",
    "  # Data flows through each layer\n",
    "\tmodel = Sequential()\n",
    "\n",
    "\t# Each Dense layer adds more parameters (256 -> 512 -> 1024), allowing the model to learn more intricate details.\n",
    "  \n",
    "\t# Input player (noise_shape 100) and hidden layer (dense(256))\n",
    "\t# Adds a layer into the model\n",
    "\t# Creates a Dense layer with 256 neurons, and expect an input of 100 numbers (noise_shape)\n",
    "\tmodel.add(Dense(256, input_shape=noise_shape))\n",
    "\n",
    "\t# Alpha is a hyperparameter that controls how much the function passes through negative network inputs\n",
    "\t# If alpha is too small, the signal is too weak and the neurons can still die\n",
    "\t# If alpha is too big, the model becomes too linear and loses its inability to learn complex shapes\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "\t# Batch normalization keeps a running average of mean and variance of the data\n",
    "\t# Momentum decides how much weight to give to the past (80%) vs. the current data (20%)\n",
    "\t# If momentum is too small, the normalization would jump around wildly with each new batch of data\n",
    "\t# Acts as stabilizer, which allows a higher learning rate\n",
    "\tmodel.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "\t# Hidden layer\n",
    "\tmodel.add(Dense(512))\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\tmodel.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "\t# Hidden layer\n",
    "\tmodel.add(Dense(1024))\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\tmodel.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "\t# np.prod multiples 28x28x1 (from img_shape) = 784\n",
    "\t# The final Dense layer creates 784 outputs - one for every pixel in the MNIST image\n",
    "\t# Tanh activation normalizes all output numbers to be between -1 and 1\n",
    "\tmodel.add(Dense(np.prod(img_shape), activation='tanh'))\n",
    "\n",
    "\t# Before, the data is a long list of 784 numbers\n",
    "\t# Reshape folds it into a 28x28 grid - turns it into an image\n",
    "\tmodel.add(Reshape(img_shape))\n",
    "\n",
    "\t# Prints a table showing the layers and number of parameters\n",
    "\tmodel.summary()\n",
    "\n",
    "\t### Functional API - USE THE MODEL ###\n",
    "\n",
    "\t# Creates the Tensorspace to accept a list of 100 numbers, the size of the seed\n",
    "\tnoise = Input(shape=noise_shape)\n",
    "\n",
    "\t# Feeds the noise through the finished model - returns the generated image\n",
    "\timg = model(noise)\n",
    "\n",
    "\t# Wrap the input, layers, and output into a single, usable object called a Model\n",
    "\treturn Model(noise, img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff93670f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given an input image, the Discriminator returns the likelihood of the image being real (binary classification)\n",
    "def build_discriminator():\n",
    "\t### SEQUENTIAL API ###\n",
    "\n",
    "\tmodel = Sequential()\n",
    "\n",
    "\t# Disciminator is the opposite of the generator, condenses from 512 -> 256\n",
    "\t# Taking 784 pieces of information and finding the most important features\n",
    "\n",
    "\t# Input layer\n",
    "\t# Dense layers cannot process 2D grids, only understand long lists of numbers\n",
    "\t# Flatten unrolls the 28x28 grid into a single flat line of 784 pixels\n",
    "\tmodel.add(Flatten(input_shape=img_shape))\n",
    "\n",
    "\t# Hidden layer\n",
    "\tmodel.add(Dense(512))\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "\t# No Batch Normalization\n",
    "\n",
    "\t# Hidden layer\n",
    "\tmodel.add(Dense(256))\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "\t# Output layer\n",
    "\t# Sigmoid activation normalizes the output between 0 and 1\n",
    "\t# 0 = fake, 1 = real\n",
    "\tmodel.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "\tmodel.summary()\n",
    "\n",
    "\t### FUNCTIONAL API ###\n",
    "\n",
    "\timg = Input(shape=img_shape)\n",
    "\tvalidity = model(img)\n",
    "\n",
    "\treturn Model(img, validity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70e04bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trains both the discriminator and the generator\n",
    "# They train one at a time (the other is locked). They take turns in phases in each epoch.\n",
    "def train(epochs, batch_size=128, save_interval=50):\n",
    "\t# Load the dataset\n",
    "\t# mnist.load_data() returns 4 things: X_train (60k images), y_train (labels), X_test (10k images), y_test (labels)\n",
    "\t# We only need X_train\n",
    "\t(X_train, _), (_, _) = mnist.load_data()\n",
    "\t\n",
    "\t# Convert to float and rescale -1 to 1\n",
    "\t# Standard digital images uses 8-bit integers, so every pixel has value 0 (black) to 255 (white)\n",
    "\t# We subtract and divide by it to linearly scale it to a new range\n",
    "\t# We are using the range -1 to 1 to match tanh activation range\n",
    "\tX_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "\t\n",
    "\t# The input to our generator and discriminator has a shape of 28x28x1\n",
    "\t# Add channels dimension (1)\n",
    "\tX_train = np.expand_dims(X_train, axis=3)\n",
    "\t\n",
    "\t# Default batch_size is 128. Half of this should be real (from MNIST) and half should be fake (from generator)\n",
    "\thalf_batch = int(batch_size / 2)\n",
    "\n",
    "\t# Loop through a number of epochs\n",
    "\tfor epoch in range(epochs):\n",
    "\n",
    "\t\t### TRAIN DISCRIMINATOR ###\n",
    "\t\t\n",
    "\t\t# Train the discriminator to distinguish between real (1) and fake (0)\n",
    "\t\t# Select a random batch of real images (MNIST), generate a set of fake images (Generator),\n",
    "\t\t# feed both into the Discriminator, and finally set the loss for real, fake, and combined\n",
    "\n",
    "\t\t# Select a random half batch of real images\n",
    "\t\t# Create a list of half_batch number of random index numbers from 0 to 60k (X_train.shape[0])\n",
    "\t\tidx = np.random.randint(0, X_train.shape[0], half_batch)\n",
    "\t\t# Selects the 64 images at the random indices we generates\n",
    "\t\timgs = X_train[idx]\n",
    "\n",
    "\t\t# Create the seeds (input for the generator), based on a normal distribution (0 mean, 1 std)\n",
    "\t\t# Create half_batch number of vectors, each of size 100\n",
    "\t\tnoise = np.random.normal(0, 1, (half_batch, 100))\n",
    "\n",
    "\t\t# The generator takes the noise and generates half_batch number of fake images\n",
    "\t\t# gen_imgs is a NumPy array with shape (half_batch, 28, 28, 1)\n",
    "\t\t# Because of the tanh activation, every pixel in these 64 images is between -1 and 1\n",
    "\t\tgen_imgs = generator.predict(noise)\n",
    "\n",
    "\t\t# Train the discriminator on real and fake images, separately (more effective)\n",
    "\t\t# Train on real images - input half_batch number of MNIST images\n",
    "\t\t# Since they are all real, the answer key is an array of 1s (np.ones((half_batch, 1)))\n",
    "\t\td_loss_real = discriminator.train_on_batch(imgs, np.ones((half_batch, 1)))\n",
    "\n",
    "\t\t# Train on generated images, with answer key of all 0s\n",
    "\t\td_loss_fake = discriminator.train_on_batch(gen_imgs, np.zeros((half_batch, 1)))\n",
    "\n",
    "\t\t# Since we trained the model twice, we average them to get a overall loss\n",
    "\t\td_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\t\t\n",
    "\t\t### TRAIN GENERATOR ###\n",
    "\t\t\n",
    "\t\t# Trains the generator to trick the discriminator by labeling fake images as real (1)\n",
    "\t\t# Discriminator is frozen so that it cannot become more forgiving to reach target, generator has to get better\n",
    "\n",
    "\t\t# Create batch_size number of noise veectors, based on normal distribution, as input for the generator\n",
    "\t\t# Output is size (batch size, 100)\n",
    "\t\tnoise = np.random.normal(0, 1, (batch_size, 100))\n",
    "\n",
    "\t\t# The generator wants the discriminator to label the generated samples as real (ones)\n",
    "\t\t# We create an array of all ones as the answer key\n",
    "\t\t# When the discriminator (correctly) labels the fake image as 0, the loss will be huge\n",
    "\t\t# Since the discriminator is locked, the generator will need to improve\n",
    "\t\tvalid_y = np.array([1] * batch_size)\n",
    "\n",
    "\t\t# The generator is trained with a combined model (linked with the discriminator)\n",
    "\t\t# because on its own, the generator doesn't have a loss function to classify real/fake\n",
    "\t\tg_loss = combined.train_on_batch(noise, valid_y)\n",
    "\n",
    "\t\t# Print the progress\n",
    "\t\tprint (\"%d [D loss: %f, acc.: %.2f%%] [G loss: %f]\" % (epoch, d_loss[0], 100*d_loss[1], g_loss))\n",
    "\n",
    "\t\t# If at save interal, save the generated image samples\n",
    "\t\tif epoch % save_interval == 0:\n",
    "\t\t\tsave_imgs(epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6adecadd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save our images for us to view\n",
    "def save_imgs(epoch):\n",
    "\t# Saving a 5x5 grid - create 25 samples\n",
    "\tr, c = 5, 5\n",
    "  \n",
    "\tnoise = np.random.normal(0, 1, (r * c, 100))\n",
    "\tgen_imgs = generator.predict(noise)\n",
    "\n",
    "\t# Rescale images to range between 0 and 1\n",
    "\t# Before, we used the range of -1 and 1, but viewing libraries expect the range 0-1\n",
    "\tgen_imgs = 0.5 * gen_imgs + 0.5\n",
    "\n",
    "\tfig, axs = plt.subplots(r, c)\n",
    "\tcnt = 0\n",
    "\tfor i in range(r):\n",
    "\t\tfor j in range(c):\n",
    "\t\t\taxs[i,j].imshow(gen_imgs[cnt, :, :, 0], cmap='gray')\n",
    "\t\t\taxs[i,j].axis('off')\n",
    "\t\t\tcnt += 1\n",
    "\tfig.savefig(\"images/mnist_%d.png\" % epoch)\n",
    "\tplt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "518f4610",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define the optimizer - updates the weights of the network when training\n",
    "# Hyperparameters (learning rate, momentum)\n",
    "#optimizer = Adam(0.0002, 0.5)\n",
    "optimizer = Adam(learning_rate=0.0001, beta_1=0.5)\n",
    "\n",
    "# Build and compile the discriminator first\n",
    "# Discriminator is an instance of the Keras Model class\n",
    "discriminator = build_discriminator()\n",
    "# Compile locks the settings for this model\n",
    "# We use binary_crossentropy because the discriminator is a binary classifier\n",
    "# Use the optimizer we defined earlier\n",
    "# Keeping track of accuracy as a metric for understanding\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Build and compile our generator\n",
    "generator = build_generator()\n",
    "# We are only generating images, so we don't need to track any metrics\n",
    "generator.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "# Defines the input parameter for the model, vector of size 100\n",
    "z = Input(shape=(100,))\n",
    "# The fake, generated image\n",
    "img = generator(z)\n",
    "\n",
    "# We lock (set to false) the discriminator trainable settings; does not impact the previously compiled settings\n",
    "# This ensures that when we combine our models, we only train the generator\n",
    "# Later when we call train, it still trains discriminator with the previous compilation settings\n",
    "# And trains combined with this setting\n",
    "discriminator.trainable = False\n",
    "\n",
    "# Feed the generated image into the discriminator and store its output in valid (real or not)\n",
    "valid = discriminator(img)\n",
    "\n",
    "# Combine the models (stack the generator and discriminator)\n",
    "# Takes the noise as input (z) -> generates images -> determines validity (valid)\n",
    "combined = Model(z, valid)\n",
    "combined.compile(loss='binary_crossentropy', optimizer=optimizer)\n",
    "\n",
    "train(epochs=30000, batch_size=64, save_interval=200)\n",
    "\n",
    "generator.save('generator_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08cc385b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "(X_train, _), (_, _) = mnist.load_data()\n",
    "X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "plt.imshow(X_train[0], cmap='gray')\n",
    "plt.show()\n",
    "print(f\"Min: {X_train.min()}, Max: {X_train.max()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "126_gan_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
