{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e50c8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras is a library that acts like a wrapper around TensorFlow, provides simple commands to use TensorFlow\n",
    "\n",
    "# keras.datasets is a library of pre-packaged sample data\n",
    "# Import MNIST database, collection of handwritten digits - the \"real\" data\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# A layer is a specific mathematical transformation that data passes through\n",
    "# Input - a placeholder for the starting data\n",
    "# Dense - a standard brick; every neuron in this layer connects to every neuron in the next\n",
    "# Reshape - a morphing brick; changes the data from a flat line into a 2D square\n",
    "# Dropout - a filter brick; randomly turns off neurons to prevent the model from overfitting\n",
    "from keras.layers import Input, Dense, Reshape, Flatten\n",
    "\n",
    "# Standardies the outputs from the previous layer to always have a mean of 0 and a standard deviation of 1\n",
    "from keras.layers import BatchNormalization\n",
    "\n",
    "# Standard ReLu turns all negative numbers into zero\n",
    "# Leaky ReLu allows a small percentage of negative signal to pass through, keeps the GAN \"alive\"\n",
    "# Original line - from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers import LeakyReLU\n",
    "\n",
    "# Defines the \"container\" for the layers\n",
    "# Sequential - A simple, linear stack what data flows through each layer\n",
    "# Model - More flexible paths\n",
    "from keras.models import Sequential, Model\n",
    "\n",
    "# The optimizer is the algorithm that updates the model's weights to make it better; Adam is a popular choice\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "be1defe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Each image in the MNIST dataset is 28x28 pixels.\n",
    "# Define input image dimensions\n",
    "img_rows = 28\n",
    "img_cols = 28\n",
    "\n",
    "# The images are in grayscale, so each pixel has 1 value describing how bright it is (black to white)\n",
    "channels = 1\n",
    "\n",
    "# Creates a tuple defining our image shape\n",
    "img_shape = (img_rows, img_cols, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "035b776a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given an input of noise (latent) vector, the Generator will generate an image\n",
    "def build_generator():\n",
    "\n",
    "\t### Sequential API - BUILD THE MODEL ###\n",
    "  \n",
    "\t# Define the noise (seed) to be a vector (1D) of size 100\n",
    "\tnoise_shape = (100,)\n",
    "  \n",
    "\t# Define the generator network\n",
    "  # Note: Current GAN is simple - only uses Dense layers (easy to understand, fast to train) - but don't see shapes well\n",
    "\t#       There are more powerful versions (e.g., VGG for super-resolution GAN)\n",
    "  \n",
    "\t# Creates an empty container to add layers into.\n",
    "  # Data flows through each layer\n",
    "\tmodel = Sequential()\n",
    "  \n",
    "\t# Adds a layer into the model - first layer, so it is in the input layer\n",
    "\t# Creates a Dense layer with 256 neurons, and expect an input of 100 numbers (noise_shape)\n",
    "\tmodel.add(Dense(256, input_shape=noise_shape))\n",
    "\n",
    "\t# Alpha is a hyperparameter that controls how much the function passes through negative network inputs\n",
    "\t# If alpha is too small, the signal is too weak and the neurons can still die\n",
    "\t# If alpha is too big, the model becomes too linear and loses its inability to learn complex shapes\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "\t# Batch normalization keeps a running average of mean and variance of the data\n",
    "\t# Momentum decides how much weight to give to the past (80%) vs. the current data (20%)\n",
    "\t# If momentum is too small, the normalization would jump around wildly with each new batch of data\n",
    "\t# Acts as stabilizer, which allows a higher learning rate\n",
    "\tmodel.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "\tmodel.add(Dense(512))\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\tmodel.add(BatchNormalization(momentum=0.8))\n",
    "\tmodel.add(Dense(1024))\n",
    "\tmodel.add(LeakyReLU(alpha=0.2))\n",
    "\tmodel.add(BatchNormalization(momentum=0.8))\n",
    "\n",
    "\t# Each Dense layer adds more parameters (256 -> 512 -> 1024), allowing the model to learn more intricate details.\n",
    "\n",
    "\t# np.prod multiples 28x28x1 (from img_shape) = 784\n",
    "\t# The final Dense layer creates 784 outputs - one for every pixel in the MNIST image\n",
    "\t# tanh activation normalizes all output numbers to be between -1 and 1\n",
    "\tmodel.add(Dense(np.prod(img_shape), activation='tanh'))\n",
    "\n",
    "\t# Before, the data is a long list of 784 numbers\n",
    "\t# Reshape folds it into a 28x28 grid - turns it into an image\n",
    "\tmodel.add(Reshape(img_shape))\n",
    "\n",
    "\t# Prints a table showing the layers and number of parameters\n",
    "\tmodel.summary()\n",
    "\n",
    "\n",
    "\t### Functional API - USE THE MODEL ###\n",
    "\n",
    "\t# Creates the Tensorspace to accept a list of 100 numbers, the size of the seed\n",
    "\tnoise = Input(shape=noise_shape)\n",
    "\n",
    "\t# Feeds the noise through the finished model - returns the generated image\n",
    "\timg = model(noise)\n",
    "\n",
    "\t# Wrap the input, layers, and output into a single, usable object called a Model\n",
    "\treturn Model(noise, img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "126_gan_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
